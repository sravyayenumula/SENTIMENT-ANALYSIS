# -*- coding: utf-8 -*-
"""SENTIMENT ANALYSIS PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/188ZN-Vku1qXUyjcvgmYYj8xhB5_6KuVu
"""

pip install --upgrade plotly

from google.colab import files
uploaded = files.upload()

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd
from sklearn.svm import SVC
import matplotlib.pyplot as plt
import time as t
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import roc_curve, auc
import seaborn as sns
import plotly.express as px
from sklearn.metrics import confusion_matrix
import sklearn.metrics as mt
import datetime as d

Reviews = pd.read_csv("Reviews.csv")
Reviews

count = Reviews.isna().sum()
count

"""#Data visualisation"""

sns.heatmap(Reviews.corr(),annot = True)

#Distribution of ratings
sns.countplot(data = Reviews , x = 'Rating')

# rating and recommendation
sns.countplot(x=Reviews['Rating'],hue = Reviews['Recommended IND'])

sns.countplot(x=Reviews['Rating'],hue = Reviews['Department Name'])

FreqOfWords = Reviews['Review Text'].str.split(expand=True).stack().value_counts()
FreqOfWords_top200 = FreqOfWords[:200]

fig = px.treemap(FreqOfWords_top200, path=[FreqOfWords_top200.index], values=0)
fig.update_layout(title_text='Top Frequent 200 Words in the Dataset (Before Cleaning)',
                  title_x=0.5, title_font=dict(size=20)
                  )
fig.update_traces(textinfo="label+value")
fig.show()

FreqOfWords = Reviews['Lemma'].str.split(expand=True).stack().value_counts()
FreqOfWords_top200 = FreqOfWords[:200]

fig = px.treemap(FreqOfWords_top200, path=[FreqOfWords_top200.index], values=0)
fig.update_layout(title_text='Top Frequent 200 Words in the Dataset (After Cleaning)',
                  title_x=0.5, title_font=dict(size=20)
                  )
fig.update_traces(textinfo="label+value")
fig.show()

from wordcloud import WordCloud
data_recommended =Reviews[Reviews['Recommended IND'] == 1]  
data_not_recommended = Reviews[Reviews['Recommended IND'] == 0] 

WordCloud_recommended = WordCloud(max_words=500,
                                  random_state=30,
                                  collocations=True,colormap='Blues').generate(str((data_recommended['Lemma'])))

plt.figure(figsize=(10, 8))
plt.imshow(WordCloud_recommended, interpolation='bilinear')
plt.title('WordCloud of the Recommended Reviews', fontsize=20)
plt.axis("off")
plt.show()

WordCloud_recommended = WordCloud(max_words=500,
                                  random_state=30,
                                  collocations=True,colormap='Spectral').generate(str((data_not_recommended['Lemma'])))

plt.figure(figsize=(10, 8))
plt.imshow(WordCloud_recommended, interpolation='bilinear')
plt.title('WordCloud of the Recommended Reviews', fontsize=20)
plt.axis("off")
plt.show()

px.scatter(Reviews, x="Age", y="Positive Feedback Count", facet_row="Recommended IND", facet_col="Rating",trendline="ols",category_orders={"Rating": [1,2,3,4,5],'Recommended IND':[0,1]})

Reviews['length_of_text'] = [len(i.split(' ')) for i in Reviews['Review Text']]
sns.histplot(Reviews['length_of_text'])

px.box(Reviews, x="Age", y="Division Name", orientation="h",color = 'Recommended IND')

sns.countplot(x=Reviews['Department Name'],hue = Reviews['Recommended IND'])

Reviews['length_of_text'] = [len(i.split(' ')) for i in Reviews['Review Text']]
fig = px.histogram(Reviews['length_of_text'], marginal='box',
                   labels={"value": "Length of the Text",
                           "color": 'Recommended'},
                   color=Reviews['Recommended IND'])

fig.update_traces(marker=dict(line=dict(color='#000000', width=2)))
fig.update_layout(title_text='Distribution of the Length of the Texts',
                  title_x=0.5, title_font=dict(size=20))
fig.update_layout(barmode='overlay')
fig.show()

sns.countplot(x=Reviews['Division Name'],hue = Reviews['Recommended IND'])

px.histogram(Reviews,x='Age')

px.histogram(Reviews, x= 'Class Name')

"""# preprocessing"""

# cleaning the text 

import re
def clean(text):
  text = re.sub('[^A-Za-z]+', ' ', text)
  return text

Reviews['Cleaned Reviews'] = Reviews['Review Text'].apply(clean)
Reviews.head()

import nltk
nltk.download('punkt')

# tokenization

import nltk
from nltk.tokenize import word_tokenize

def Word_tokenize(text):
  return word_tokenize(text)

Reviews['token Reviews'] = Reviews['Cleaned Reviews'].apply(Word_tokenize)

Reviews.head()

import nltk
nltk.download('averaged_perceptron_tagger')

nltk.download('stopwords')
from nltk.corpus import stopwords
nltk.download('wordnet')
from nltk.corpus import wordnet
from nltk import pos_tag


pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}
def token_stop_pos(text):
    tags = pos_tag(word_tokenize(text))
    newlist = []
    for word, tag in tags:
      if word.lower() not in set(stopwords.words('english')):
        newlist.append(tuple([word, pos_dict.get(tag[0])]))
    return newlist

Reviews['POS tagged'] = Reviews['Cleaned Reviews'].apply(token_stop_pos)
Reviews.head()

from nltk.stem import WordNetLemmatizer
wordnet_lemmatizer = WordNetLemmatizer()
def lemmatize(pos_data):
    lemma_rew = " "
    for word, pos in pos_data:
      if not pos:
        lemma = word
        lemma_rew = lemma_rew + " " + lemma
      else:
        lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)
        lemma_rew = lemma_rew + " " + lemma
    return lemma_rew

Reviews['Lemma'] = Reviews['POS tagged'].apply(lemmatize)
Reviews.head()

def sentiment(i):
  if i == 3:
    return 'Neutral'
  elif i<3:
    return 'Negative'
  else:
    return 'Positive'

Reviews['Sentiment'] = Reviews['Rating'].apply(sentiment)
Reviews.head()

"""#Classifiers"""

vectorizer = CountVectorizer()

train_data,test_data = train_test_split(Reviews,test_size=0.3)

X_train = vectorizer.fit_transform(train_data["Review Text"].fillna(' '))

y_train = train_data['Sentiment']

X_test = vectorizer.transform(test_data["Review Text"].fillna(' '))

y_test = test_data['Sentiment']

#MLP
start=d.datetime.now()
nn = MLPClassifier(alpha=0.002,solver='lbfgs',random_state=1,learning_rate_init=0.25)
nn.fit(X_train, y_train)
pred = nn.predict(X_test)
print('Elapsed time: ',str(d.datetime.now()-start))
print('Accracy score:',mt.accuracy_score(y_test, pred))

#SVM
start=d.datetime.now()
svm = SVC()
svm.fit(X_train, y_train)
pred = svm.predict(X_test)
print('Elapsed time: ',str(d.datetime.now()-start))
print('Accracy score:',mt.accuracy_score(y_test, pred))

#KNN
start=d.datetime.now()
from sklearn.neighbors import KNeighborsClassifier
neigh = KNeighborsClassifier(n_neighbors=3)
neigh.fit(X_train, y_train)
pred = neigh.predict(X_test)
print('Elapsed time: ',str(d.datetime.now()-start))
print('Accracy score:',mt.accuracy_score(y_test, pred))

#logistic Regression
start=d.datetime.now()
lr = LogisticRegression(tol=0.002)
lr.fit(X_train, y_train)
pred = lr.predict(X_test)
print('Elapsed time: ',str(d.datetime.now()-start))
print('Accracy score:',mt.accuracy_score(y_test, pred))

#naive bayes
start=d.datetime.now()
nb= MultinomialNB()
nb.fit(X_train, y_train)
pred = nb.predict(X_test)
print('Elapsed time: ',str(d.datetime.now()-start))
print('Accracy score:',mt.accuracy_score(y_test, pred))

# decision tree
start=d.datetime.now()
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
pred = dt.predict(X_test)
print('Elapsed time: ',str(d.datetime.now()-start))
print('Accracy score:',mt.accuracy_score(y_test, pred))

lr_cm=confusion_matrix(y_test.values, lr.predict(X_test))
nb_cm=confusion_matrix(y_test.values, nb.predict(X_test))
svm_cm=confusion_matrix(y_test.values, svm.predict(X_test))
nn_cm=confusion_matrix(y_test.values, nn.predict(X_test))
knn_cm=confusion_matrix(y_test.values, neigh.predict(X_test))
dt_cm=confusion_matrix(y_test.values, dt.predict(X_test))
plt.figure(figsize=(15,12))
plt.suptitle("Confusion Matrices",fontsize=24)

plt.subplot(2,2,1)
plt.title("Logistic Regression")
sns.heatmap(lr_cm, annot = True, cmap="Blues",cbar=False);
plt.xlabel('Predicted Value')
plt.ylabel('Actual Value')

plt.subplot(2,2,2)
plt.title("Naive Bayes")
sns.heatmap(nb_cm, annot = True, cmap="pink",cbar=False);
plt.xlabel('Predicted Value')
plt.ylabel('Actual Value')

plt.subplot(2,2,3)
plt.title("Support Vector Machine (SVM)")
sns.heatmap(svm_cm, annot = True, cmap="inferno",cbar=False);
plt.xlabel('Predicted Value')
plt.ylabel('Actual Value')

plt.subplot(2,2,4)
plt.title("Neural Network")
sns.heatmap(nn_cm, annot = True, cmap="cividis",cbar=False);
plt.xlabel('Predicted Value')
plt.ylabel('Actual Value')

plt.figure(figsize=(15,12))
plt.suptitle("Confusion Matrices",fontsize=24)
plt.subplot(2,2,1)
plt.title("KNN")
sns.heatmap(knn_cm, annot = True, cmap="Wistia_r",cbar=False);
plt.xlabel('Predicted Value')
plt.ylabel('Actual Value')

plt.subplot(2,2,2)
plt.title("Decision Tree")
sns.heatmap(dt_cm, annot = True, cmap="Spectral",cbar=False);
plt.xlabel('Predicted Value')
plt.ylabel('Actual Value')

print("Logistic Regression")
print(mt.classification_report(y_test, lr.predict(X_test)))
print("\n Naive Bayes")
print(mt.classification_report(y_test, nb.predict(X_test)))
print("\n Support Vector Machine (SVM)")
print(mt.classification_report(y_test, svm.predict(X_test)))
print("\n Neural Network")
print(mt.classification_report(y_test, nn.predict(X_test)))
print("\n KNN")
print(mt.classification_report(y_test, neigh.predict(X_test)))
print("\n Decision Tree")
print(mt.classification_report(y_test, dt.predict(X_test)))